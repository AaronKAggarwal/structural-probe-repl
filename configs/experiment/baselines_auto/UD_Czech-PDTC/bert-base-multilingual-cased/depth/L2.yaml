# Auto-generated by generate_configs.py
name: baselines_auto/bert-base-multilingual-cased/depth/L2

defaults:
  - _self_
  - /dataset: UD_Czech-PDTC/UD_Czech-PDTC
  - /embeddings: UD_Czech-PDTC/bert-base-multilingual-cased/L2
  - /probe: depth
  - /probe_rank@probe: "128"
  - /training: adam_modern_scheduler
  - /evaluation: default
  - /runtime: mps
  - /logging: UD_Czech-PDTC_bert-base-multilingual-cased/depth_L2

# Per-experiment training cadence (tests and real runs)
training:
  eval_every_n_epochs: 1
  eval_on_train_every_n_epochs: 40

evaluation:
  metrics: ["spearmanr_hm", "root_acc"]

logging:
  experiment_name: "UD_CZECH-PDTC_BERT-BASE-MULTILINGUAL-CASED_L2_DEPTH_R128"