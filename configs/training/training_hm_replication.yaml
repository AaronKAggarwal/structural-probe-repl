# configs/training/training_hm_replication.yaml
# Inherits optimizer settings from adam.yaml.
# Only specifies values unique to the H&M replication training schedule.

batch_size: 20
patience: 10
early_stopping_metric: "loss" # Hewitt & Manning monitored dev loss
# vvv NOT IN H&M. ONLY USE FOR FASTER TESTING vvv
# early_stopping_delta: 0.0001 # NOT IN H&M. ONLY USE FOR FASTER TESTING.
# ^^^ NOT IN H&M. ONLY USE FOR FASTER TESTING ^^^

# This overrides the lr_scheduler_with_reset block from schedule_hm.yaml
lr_scheduler_with_reset:
  enable: true
  lr_decay_factor: 0.1
  lr_decay_patience: 1 # This was key for H&M style: decay if no improvement in 1 epoch
  min_lr: 1.0e-6