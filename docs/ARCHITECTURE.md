# Repository Architecture

Last updated: 2025-05-26

This document explains the layout of the `structural-probe-repl` project, covering the vendored original Hewitt & Manning (2019) codebase and the new, modern PyTorch implementation.

## 1. Original Hewitt & Manning Code (Vendored)

*   **Location:** `src/legacy/structural_probe/`
*   **Description:** A direct copy of the original codebase from `john-hewitt/structural-probes` (GitHub). This code is PyTorch-based (approx. v1.0-1.3). It was used in Phase 0a to verify the original probing pipeline.
*   **Key Subdirectories & Files:**
    *   **`README.md` / `LICENSE`:** Original project's overview and license.
    *   **`doc-assets/`:** Figures used in the original H&M README/paper.
    *   **`download_example.sh`:** Original script to fetch sample data. (Note: URLs are dead; data was sourced from the `whykay-01` fork for Phase 0a).
    *   **`example/`:**
        *   `config/`: YAML configurations for H&M's experiments (e.g., `prd_en_ewt-ud-sample.yaml`, PTB configs in `naacl19/`).
        *   `data/`: Contains the EWT sample data (`en_ewt-ud-sample/` subdirectory with `.conllu`, `.txt`, `.elmo-layers.hdf5` files) and pre-trained BERT probe parameters (`bertlarge16-*.params`), all sourced from the `whykay-01` fork.
        *   `demo-bert.yaml`: Configuration for the BERT demo script.
    *   **`requirements.txt`:** Original Python dependencies (excluding PyTorch, which was to be installed separately).
    *   **`scripts/`:** Original data preparation utilities (e.g., `convert_conll_to_raw.py`, `convert_raw_to_elmo.sh`, `convert_raw_to_bert.py`).
    *   **`structural-probes/`:** The core Python modules of the H&M probe:
        *   `data.py`: Data loading (CoNLLU, HDF5). The version used in our Phase 0a runs is the original H&M version.
        *   `model.py`: Model definition (mainly for pre-computed embeddings).
        *   `probe.py`: Probe `nn.Module` definitions.
        *   `loss.py`: Loss function definitions.
        *   `regimen.py`: Training loop logic.
        *   `reporter.py`: Evaluation metric calculation and reporting.
        *   `task.py`: Defines linguistic tasks (distance, depth) and gold label extraction.
        *   `run_experiment.py`, `run_demo.py`: Main scripts for training and demos.

## 2. Modern Probe Implementation & Project Scaffold

This section details the structure of the current project, including the modern PyTorch re-implementation.

*   **`configs/`**: Hydra configuration files for the modern probing framework.
    *   `config.yaml`: Main default configuration.
    *   `dataset/`: Configs defining different datasets (e.g., `elmo_ewt_sample_whykay01.yaml` pointing to vendored CoNLLU, `elmo_ewt_MY_sample.yaml` pointing to `data_staging` CoNLLU).
    *   `embeddings/`: Configs defining different sources of pre-computed embeddings (e.g., `elmo_l2_whykay01.yaml` for vendored HDF5s, `elmo_l2_my_sample_modern_prep.yaml` for self-generated HDF5s).
    *   `experiment/`: Composable experiment configurations (e.g., `elmo_ewt_dist_phase1_train.yaml`).
    *   `probe/`: Configs for different probe types and hyperparameters (e.g., `distance_rank32.yaml`).
    *   `training/`: Configs for training loop parameters (e.g., `default_adam.yaml`).
    *   `evaluation/`: Configs for evaluation settings (less used currently).

*   **`data/`**: (Gitignored by default, intended for large primary datasets)
    *   *(Planned)* Location for storing primary datasets like the full Penn Treebank (PTB) once acquired and processed.

*   **`data_staging/`**: (Gitignored)
    *   Local staging area for downloading full datasets (e.g., `ud_ewt_full/`) and for intermediate files during sample data preparation (e.g., `my_ewt_sample_for_legacy_probe/`, `modern_elmo_prep/`).

*   **`docs/`**: All project documentation. See `docs/DOC_INDEX.md` for a full map.

*   **`env/`**: Dockerfiles for containerized environments.
    *   `Dockerfile.legacy_pt_cpu`: Defines the environment for running the original H&M code (Phase 0a).
    *   *(Planned: `Dockerfile.cuda` for modern probe on NVIDIA GPUs).*

*   **`outputs/`**: (Gitignored by default)
    *   Default root directory where Hydra saves outputs for each run (logs, configs, checkpoints, metrics). Typically structured as `outputs/YYYY-MM-DD/HH-MM-SS/`.

*   **`results_staging/`**: (Gitignored)
    *   Local directory used for mounting and inspecting results generated by Docker container runs (especially from Phase 0a).

*   **`scripts/`**: Executable Python and shell scripts for the project.
    *   **Legacy Support:**
        *   `check_legacy_env.sh`: Health check for the `probe:legacy_pt_cpu` container.
        *   `run_legacy_probe.sh`: Wrapper to run H&M's `run_experiment.py` or `run_demo.py` inside the legacy container.
    *   **Data Preparation (for samples):**
        *   `create_conllu_sample.py`: Generates small CoNLLU samples from larger files.
        *   `convert_sample_conllu_to_raw.py`: Converts sample CoNLLU to raw text for ELMo.
        *   `generate_elmo_embeddings_for_sample.sh`: Generates ELMo HDF5s for samples using AllenNLP in Docker.
    *   **Modern Probe Pipeline:**
        *   `train_probe.py`: Main Hydra-configurable script for training and evaluating modern structural probes (Phase 1 deliverable).
    *   *(Planned: `extract_embeddings.py` for modern LLMs in Phase 2).*

*   **`src/`**: Source code for the project.
    *   `legacy/structural_probe/`: Contains the vendored original Hewitt & Manning codebase (details in Section 1).
    *   `torch_probe/`: Houses the modern PyTorch (v2.x) re-implementation of the structural probe and associated utilities (Phase 1 deliverables).
        *   `utils/`: Utility modules for the modern probe.
            *   `conllu_reader.py`: Parses CoNLL-U files, focusing on syntactic tokens.
            *   `gold_labels.py`: Computes gold tree depths and pairwise distances.
            *   `embedding_loader.py`: Loads pre-computed embeddings from HDF5.
        *   `dataset.py`: Defines `ProbeDataset` (PyTorch Dataset) and `collate_probe_batch`.
        *   `probe_models.py`: Defines `DistanceProbe` and `DepthProbe` as `nn.Module`s.
        *   `loss_functions.py`: Custom L1 loss functions for distance and depth tasks.
        *   `evaluate.py`: Functions for calculating metrics (Spearman, UUAS, Root Accuracy) with punctuation filtering.
        *   `train_utils.py`: Helpers for training (optimizer, early stopping, checkpointing).
    *   *(Planned: `src/common/` for utilities shared across different probe types or experiments).*
    *   *(Planned: `src/extraction/` for modern LLM hidden state extraction logic).*

*   **`tests/`**: Contains all tests for the project.
    *   `smoke/`: Basic integration tests for pipelines.
        *   `test_probe_pipeline_smoke.py`: Runs a minimal version of `scripts/train_probe.py`.
    *   `unit/torch_probe/`: Unit tests for individual modules in `src/torch_probe/`.
        *   Includes tests for `conllu_reader`, `dataset`, `embedding_loader`, `evaluate`, `gold_labels`, `loss_functions`, `probe_models`, `train_utils`.
        *   Contains both self-written tests and independent test suites provided by collaborators.

*   **Root Directory Files:**
    *   `README.md`: Main project entry point.
    *   `pyproject.toml`, `poetry.lock`: Poetry dependency and project management.
    *   `requirements-mps.txt`: Exported requirements for the native macOS MPS environment.
    *   `.gitignore`: Specifies intentionally untracked files.
    *   *(Future: `CONTRIBUTING.md`, `CHANGELOG.md`, `LICENSE` for this project's code).*

---